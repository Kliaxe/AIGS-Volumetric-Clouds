# ================================================================
# Volumetric Clouds Training Configuration - Experiment 2 (Data Efficiency, Single View)
# ================================================================

# Single-view dataset (pre-rendered).
name: exp2_data_efficiency_singleview  # Label for this configuration; used in output paths.

common_model: &common_model
  model_base_channels: 32      # Base number of channels in the UNet.
  model_bilinear: true         # Use bilinear upsampling in the decoder.
  model_learn_residual: true   # Predict residual w.r.t. input.

common_split: &common_split
  train_fraction: 0.8   # Fraction of samples for training split.
  val_fraction: 0.15    # Fraction of samples for validation split.
  test_fraction: 0.05   # Fraction of samples for test split.
  split_seed: 12345     # Fixed seed for deterministic split.

common_aux: &common_aux
  use_view_transmittance: false
  use_light_transmittance: false
  use_linear_depth: false
  use_normals: false
  depth_normalization_max: 70000.0  # Depth normalization scale.

train:
  # Merge shared defaults; fields below can override them if needed.
  <<: [*common_model, *common_split, *common_aux]

  data_dir: TrainingCaptures_Single  # Single-view dataset root.
  output_dir: outputs                # Base output directory (repo-root).

  # Training schedule ---------------------------------------------------------
  epochs: 100          # Shared schedule across all dataset sizes.
  batch_size: 64       # Batch size for training.
  learning_rate: 0.00005  # Learning rate for optimizer.
  crop_size: 256       # Training crop size.
  limit_pairs: null    # Overridden per-experiment to control dataset size.

  # Loss configuration ---------------------------------------------------------
  use_auxiliary_in_loss: false  # Plain RGB L1 loss; auxiliary buffers only affect inputs.

  # Runtime behaviour ---------------------------------------------------------
  num_workers: 4            # Number of data loader workers.
  device: cuda              # Training device.
  save_epoch_stride: 20     # Checkpoint stride.
  save_every_n_steps: 8192  # Step-based checkpoint stride.
  log_every_n_steps: 256    # Logging stride.
  save_only_last_epoch: false  # Keep intermediate checkpoints.
  export_every_n_epochs: 50    # Export loss curves regularly.

  # Experiment grid -----------------------------------------------------------
  # Compare RGB-only against a richer buffer combination across dataset sizes.
  experiments:
    # RGB-only baseline across dataset sizes.
    - name: rgb_pairs_100
      use_view_transmittance: false
      use_light_transmittance: false
      use_linear_depth: false
      use_normals: false
      limit_pairs: 100

    - name: rgb_pairs_300
      use_view_transmittance: false
      use_light_transmittance: false
      use_linear_depth: false
      use_normals: false
      limit_pairs: 300

    - name: rgb_pairs_1000
      use_view_transmittance: false
      use_light_transmittance: false
      use_linear_depth: false
      use_normals: false
      limit_pairs: null

    # Rich buffer configuration (RGB + view transmittance + normals) across sizes.
    - name: rich_pairs_100
      use_view_transmittance: true
      use_light_transmittance: false
      use_linear_depth: false
      use_normals: true
      limit_pairs: 100

    - name: rich_pairs_300
      use_view_transmittance: true
      use_light_transmittance: false
      use_linear_depth: false
      use_normals: true
      limit_pairs: 300

    - name: rich_pairs_1000
      use_view_transmittance: true
      use_light_transmittance: false
      use_linear_depth: false
      use_normals: true
      limit_pairs: null

infer:
  # Model checkpoint to use for inference (can be updated as needed).
  checkpoint: outputs/checkpoints/unet_epoch_100.pt

  # Model configuration ---------------------------------------------------------
  <<: [*common_model, *common_split, *common_aux]

  # Inference input settings ----------------------------------------------------
  input: TrainingCaptures_Single  # Same dataset root as training.
  input_glob: "*_low.pfm"         # Pattern for low-resolution inputs.
  split_mode: test                    # Evaluate on test split.
  split_sample_index: 0               # First test sample only (can be changed).
  recursive: false                    # Non-recursive search.

  # Output directory and naming -------------------------------------------------
  output_dir: outputs/infer
  output_suffix: "_pred"

  # Optional experiment-aware inference ---------------------------------------
  experiment_name: rgb_pairs_1000    # Default experiment label for inference.
  checkpoint_dir: outputs/exp2_data_efficiency_singleview/experiments/rgb_pairs_1000/checkpoints
  checkpoint_glob: "unet_epoch_*.pt"
  run_all_checkpoints: true
  run_all_experiments: true

  # Runtime behaviour -----------------------------------------------------------
  device: cuda
  upsample_mode: bicubic
  align_corners: false
  clamp_min: 0.0
  clamp_max: 1.0
  scale_factor: 4


